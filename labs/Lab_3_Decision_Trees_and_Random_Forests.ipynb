{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkkb_7LYKsG4"
      },
      "source": [
        "## **Name:** First Last\n",
        "\n",
        "## **Computing ID:** ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DAOPfwqMV5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091266c2-e509-47e5-f367-21b0c9271964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=6668c85c9f5e2efaa085066e8389ec24d333bcff8a2676bcaa2bc3acc91ad3b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "!pip install lime\n",
        "from lime import lime_tabular\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Below is a new package needed for this lab\n",
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4A9sts1JrTc"
      },
      "source": [
        "# Lab 3: Decision Trees and Random Forests (100 Points)\n",
        "##**Due November 10th, 2025 at 11:59PM**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this lab is to optimize Decision Tree and Random Forest models using the provided dataset on census level data. Your goal is to build a Random Forest Classifier to be able to predict income levels above or below 50k.\n",
        "\n",
        "The guidance this week is less prescriptive in terms of steps, so use the skills you have gained over the semester to build and evaluate your models. You will be graded on your model building, interpretation of the results and explanation of model selection. As always, you are welcome to rely on your classmates but submit your own code. Lastly, there are likely several correct approaches involving a variety of different conclusions, just make sure your conclusions are supported by your approach."
      ],
      "metadata": {
        "id": "v2MiKceoh6yF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The dataset should be familiar as it's the census data, on 48,000+ individuals with a variety of variables and a target variable for above or below 50k in salary."
      ],
      "metadata": {
        "id": "NRIThjiWiZcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.coopercenter.org/sites/default/files/styles/wide/public/wordpress_import/Figure1CesnsuBlog2-1024x512_0.png?itok=DwYqkfFm)"
      ],
      "metadata": {
        "id": "rcS_RpJ-D2JS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look through the data dictionary at its source link: https://archive.ics.uci.edu/ml/datasets/Adult"
      ],
      "metadata": {
        "id": "UGBaGTi8EDy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Data Preparation and EDA (15 points)**"
      ],
      "metadata": {
        "id": "h_LpB5eWiTF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a text cell, answer the following exploratory questions and support your observations with any code, if needed."
      ],
      "metadata": {
        "id": "lJdA3izfjZKn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4xxMTbVTIUP"
      },
      "source": [
        "## **Question 1 (2 points):**\n",
        "## Read in the features (X) as a Pandas DataFrame. Show the first 5 rows of the features. How many rows do you have?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "X = adult.data.features\n",
        "y = adult.data.targets"
      ],
      "metadata": {
        "id": "tR9XKw-xiZN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HefBwSXYnjdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is a total of...**"
      ],
      "metadata": {
        "id": "IGjYDY6O-EIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 2 (2 points):**\n",
        "## Are there any potential issues in the data or target that need to be corrected? Why are they issues? What specific method would you use to correct them and why?\n",
        "\n",
        "## Consider using code and reading the data description (https://archive.ics.uci.edu/dataset/2/adult) to explore:\n",
        "\n",
        "*   Assumptions and ranges of collected data\n",
        "*   Missing values (impute? drop?)\n",
        "*   Numerical data types represented as strings\n",
        "*   Encoding categorical data appropriately\n",
        "*   Normalization\n",
        "*   Standardization\n",
        "\n",
        "## You will not need to consider feature imbalances or sampling in part 1 or 2 of the lab."
      ],
      "metadata": {
        "id": "lGZ8stUWmnjx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MeiqvF3Bvhd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Potential Issues:** Potential issues I've identified are...."
      ],
      "metadata": {
        "id": "CHa_7vvUvhmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3 (6 points):**\n",
        "## Preprocess the data according to the issues and correction methods you've identified. Save the new features and target variable (if necessary) as X_clean and y_clean."
      ],
      "metadata": {
        "id": "j2jZGG56tWJL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9w3aWLHutsO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 4 (5 points):**\n",
        "## Create 2 versions of y_clean to create a new target response of whether income is above or below $50,000 for classification.\n",
        "\n",
        "1.   **y_clean_binary:** Recode y_clean to be 1 if the target is over or equal to 50,000\n",
        "2.   **y_clean_string:** Recode y_clean to be \"Above or Equal\" if the target is over or equal to 50,000 and \"Below\" if under.\n",
        "\n"
      ],
      "metadata": {
        "id": "o8-qUf-awWxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S1qN_IGBw6Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15fvjC_zJwzl"
      },
      "source": [
        "# **Part 2: Decision Tree Pruning, Tuning and Evaluation (30 Points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 1 (5 points):**\n",
        "## Create a function to take in a feature variable (X) and (y). In this function, do the following:\n",
        "* Create a train test split with a random seed of 3001.\n",
        "* Use a vanilla decision tree model to fit the model on the train set and predict on the test set.\n",
        "* Print the precision, recall, and accuracy of the model after prediction.\n",
        "\n",
        "## Test your function on both y_clean_binary and y_clean_string. For any of the following questions, you may use whichever y_clean variable you'd like.\n"
      ],
      "metadata": {
        "id": "iROGO6AfxF_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54bGHi5ljxVh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 2 (5 points):**\n",
        "## Adjust your function to include some plotting features. After your prediction code, plot:\n",
        "\n",
        "1.   A visualization of the resulting Decision Tree\n",
        "2.   A confusion matrix of the results\n",
        "\n",
        "## Your tree might be overwhelming or very large! If it is too large to be interpreted, constrain the max_depth parameter manually to 5 or less."
      ],
      "metadata": {
        "id": "5eab2kFezHc1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4h0vpoH0KHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3 (5 points):**\n",
        "## Create a sorted list of feature importances and comment on the top features.Plot your feature importances in a horizontal or vertical bar chart from most to least important. Label each bar with its feature importance rounded to the nearest integer (ie: 30%).\n",
        "\n",
        "## Are there a few that seem to be more important than the others?"
      ],
      "metadata": {
        "id": "deZSWbPc0QrG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZFXl7yg1H_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yes, ...**"
      ],
      "metadata": {
        "id": "1tdtqgq_1mZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 4 (5 points):**\n",
        "## Write at least 5 sentences interpreting the results of your decision tree, confusion matrix, and feature importance visualizations.\n",
        "\n",
        "## Is there any aspect of your results that you are uncertain or unsure of?"
      ],
      "metadata": {
        "id": "8TIl43ki1KfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My results show...**"
      ],
      "metadata": {
        "id": "-iAevtjt1qH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 5 (5 points):**\n",
        "## Finally, we will create a new function to tune your decision tree to get more accurate and efficient results. Update your function to take in several new parameters with these default values:\n",
        "* criterion_val ='gini'\n",
        "* splitter_val ='best'\n",
        "* max_depth_val = None\n",
        "* min_samples_split_val = 2\n",
        "* min_samples_leaf_val =1\n",
        "\n",
        "## Pass your own variable into the decision tree by specifying what sklearn parameter you are trying to tune. This will simply be the parameter without the \"_val\" suffix.\n",
        "\n",
        "## **For example, if your vanilla decision tree variable is called clf, you would adjust it like this:**\n",
        "`clf = DecisionTreeClassifier(criterion=criterion_val, splitter=splitter_val, ...)`"
      ],
      "metadata": {
        "id": "suVYIRfZ13wa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vVnFYpg5XsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 6 (5 points):**\n",
        "\n",
        "## Call your new function with either clean y variable at least 3 times. Each time, vary the values for all the parameters and examine its effects on your tree, confusion matrix, and metrics.\n",
        "\n",
        "You will likely want to look at documentation to see accepted values: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "## Why did you pick the values you did? What combination had the best effect on accuracy? Were you surprised by any of the results?"
      ],
      "metadata": {
        "id": "GVieDlFW5ZP7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CzFruwY06Cdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My stategy was to first pick...**"
      ],
      "metadata": {
        "id": "9ahsPeNh1yRn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU2O0tkmoaxB"
      },
      "source": [
        "# **Part 3: Random Forest and Ensembling Evaluation (40 Points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Parts 3 and 4, you may pick *your own dataset* or continue with the census data.\n",
        "\n",
        "## Like above, you will want to reference the documentation as necessary:\n",
        "### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ],
      "metadata": {
        "id": "i6mkGJoJ6GFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Data**\n",
        "## Use this space to load and call your data for Parts 3 and 4. You are welcome to use your final project data for these sections."
      ],
      "metadata": {
        "id": "6MueGJiy9FCA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLrhnYjJ9MfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 1 (10 points):**\n",
        "\n",
        "## Write a function to take in a feature variable (X) and a target variable (y). In the function, do the following:\n",
        "\n",
        "* Create a train test split for the variables.\n",
        "* Instantiate, fit, and predict using a vanilla Decision Tree\n",
        "* Instantiate, fit, and predict using a vanilla Random Forest classifier.\n",
        "* Return and print the accuracy, precision, and recall for both models in any format you wish.\n",
        "\n",
        "## Call your function and describe your baseline results.\n"
      ],
      "metadata": {
        "id": "YtvUV-_-6YJI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUKXGEdj7Gmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fokxO-rd_1iy"
      },
      "source": [
        "\n",
        "## **Question 2 (30 points):**\n",
        "## This question will ask you to tune Random Forest classifiers and preprocess your data in *any number of ways* to achieve the *best possible results you can*.\n",
        "\n",
        "## Train one vanilla Decision Forest model and one vanilla Random Forest model and store their accuracies in variables so you can use them as baselines.\n",
        "\n",
        "## Then, using functions or not, spend some time tuning at least 10 (or more) Random Forest models. Store your accuracies in a list or array and print your maximum accuracy.\n",
        "\n",
        "# **Go crazy - feel free to implement sampling, dropping features, preprocessing, new parameters, whatever might boost your accuracy.**\n",
        "\n",
        "# **The top 5 best accuracies in the class will get +15 on their individual lab grade!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoIceowS96Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 4: Ensemble Model Interpretation and Reflection (15 Points)**"
      ],
      "metadata": {
        "id": "F062_6a-uWcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Question 1 (5 points):**\n",
        "## Create a plot that summarizes the results of your experiments and how they compare to the results of your baseline Decision Tree and Random Forest model.\n",
        "\n",
        "## You may visualize your results in any type of plot you see fit. Color code your visual in some way so that models that did better than the baseline Random Forest are distinguished from models that did worse."
      ],
      "metadata": {
        "id": "bHehwo4A9kC6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbP54dpqAwhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 2 (5 points):**\n",
        "## Write 10 or more sentences on what parameters had the biggest effect or did not seem to effect your results. Did any parameter choices make your results worse than your vanilla model?"
      ],
      "metadata": {
        "id": "rSi6oVEUA08m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The parameters I chose...**"
      ],
      "metadata": {
        "id": "maS0GW-T_OWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3 (5 points):**\n",
        "## Write at least 5 sentences reflecting on the tuning process. A few prompts you might choose to answer are below:\n",
        "\n",
        "*  What kind of approach did you take?\n",
        "* Was it random combinations or more structured?\n",
        "* Did you change your approach after seeing your initial results?\n",
        "*  What kind of strategies in preprocessing and picking parameters (ie: brute forcing parameters, testing various values in a range) do you think would get some of the best scores in the class?"
      ],
      "metadata": {
        "id": "1WgKg9RQBM6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My approach to tuning...**"
      ],
      "metadata": {
        "id": "_SHxosC2BhTJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1KiVMvjNKGU"
      },
      "source": [
        "### Honor Pledge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo-hwQo5LBAk"
      },
      "source": [
        "On my honor as a student, I have neither given nor received unauthorized aid on this assignment."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}